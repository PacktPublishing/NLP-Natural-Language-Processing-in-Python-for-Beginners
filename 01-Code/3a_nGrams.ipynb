{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import re\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGrams(doc_string_or_list,n,docIsAlreadyTokenized):\n",
    "    doc = doc_string_or_list\n",
    "    if not docIsAlreadyTokenized:\n",
    "        doc = [token.text for token in nlp(doc_string_or_list)]\n",
    "    doc = ' '.join(doc).lower().split(' ')\n",
    "    grams = [doc[i:i+n] for i in range(len(doc)-n+1)]\n",
    "    return grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = 'how old are you today or can you tell me something about you'\n",
    "n = 4\n",
    "grams = nGrams(doc,n,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how', 'old', 'are', 'you'], ['old', 'are', 'you', 'today'], ['are', 'you', 'today', 'or'], ['you', 'today', 'or', 'can'], ['today', 'or', 'can', 'you'], ['or', 'can', 'you', 'tell'], ['can', 'you', 'tell', 'me'], ['you', 'tell', 'me', 'something'], ['tell', 'me', 'something', 'about'], ['me', 'something', 'about', 'you']]\n"
     ]
    }
   ],
   "source": [
    "print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildModel():\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateCount(nGram,model):\n",
    "    w_1_to_n_minus_1 = tuple(nGram[:-1])\n",
    "    w_n = nGram[-1]\n",
    "    model[w_1_to_n_minus_1][w_n]+=1\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeProbability(model):\n",
    "    for w_1_to_n_minus_1 in model:\n",
    "        totalCount = float(sum(model[w_1_to_n_minus_1].values()))\n",
    "        for w_n in model[w_1_to_n_minus_1]:\n",
    "            model[w_1_to_n_minus_1][w_n] /= totalCount\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model,fileNameDotpkl):\n",
    "    with open(fileNameDotpkl,'wb') as f:\n",
    "        dill.dump(model,f)\n",
    "\n",
    "def loadModel(fileNameDotpkl):\n",
    "    with open(fileNameDotpkl,'rb') as f:\n",
    "        model = dill.load(f)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups as getData\n",
    "from nltk.corpus import reuters as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = getData(subset='train',remove=('headers','footers','qoutes'),return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(X[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "model = buildModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in X:\n",
    "    for nGram in nGrams(doc,n,False):\n",
    "        model = updateCount(nGram,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in corpus.sents():\n",
    "    for nGram in nGrams(sentence,n,True):\n",
    "        model = updateCount(nGram,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = computeProbability(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveModel(model,'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n"
     ]
    }
   ],
   "source": [
    "text = ['after','that']\n",
    "nextWords = list(model[tuple(text[-n+1:])].keys())\n",
    "probs = list(model[tuple(text[-n+1:])].values())\n",
    "nextWord = np.random.choice(nextWords,1,probs)[0]\n",
    "print(nextWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleText(model,startingText=['after','that'],mxLenght = 100,nGramSize=3):\n",
    "    text = startingText\n",
    "    n = nGramSize\n",
    "    while not len(text)>mxLenght:\n",
    "        nextWords = list(model[tuple(text[-n+1:])].keys())\n",
    "        probs = list(model[tuple(text[-n+1:])].values())\n",
    "        if len(nextWords) > 0:\n",
    "            nextWord = np.random.choice(nextWords,1,probs)[0]\n",
    "            text.append(nextWord)\n",
    "        else:\n",
    "            break\n",
    "    sampled = ' '.join(text)\n",
    "    return sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "due to radioactive decay \" , presumably from his experience with miserable weather .\n"
     ]
    }
   ],
   "source": [
    "for sents in nlp(sampleText(model,['due','to'])).sents:\n",
    "    print(sents)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
