{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups as getData\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = getData(subset='train',remove=('headers','footers','quotes'),return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = defaultdict(int)\n",
    "for doc in X:\n",
    "    for token in re.split('\\W+',doc.lower()):\n",
    "        fr[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutOffValue = 10\n",
    "processed_corpus = []\n",
    "for doc in X:\n",
    "    for token in re.split('\\W+',doc.lower()):\n",
    "        if fr[token] >= cutOffValue:\n",
    "            processed_corpus.append(token)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allWords = np.array(list(fr.keys()))\n",
    "allCounts = np.array(list(fr.values()))\n",
    "vocab = allWords[allCounts >= cutOffValue]\n",
    "wordCounts = allCounts[allCounts >= cutOffValue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.75\n",
    "wordCounts = wordCounts**alpha\n",
    "probs = wordCounts/np.sum(wordCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = len(vocab)\n",
    "W2I = dict(zip(vocab,np.arange(numWords)))\n",
    "I2W = dict(zip(np.arange(numWords),vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientStep(w,cPos,cNeg,lr=0.001):\n",
    "    cPos_new = cPos - lr*(sigmoid(w.dot(cPos))-1)*w\n",
    "    w_new = w - lr*(sigmoid(w.dot(cPos))-1)*cPos\n",
    "    cNeg_new = np.zeros(cNeg.shape)\n",
    "    for i in range(cNeg.shape[0]):\n",
    "        v = sigmoid(cNeg[i,:].dot(w))\n",
    "        w_new -= lr*v*cNeg[i,:]\n",
    "        cNeg_new[i,:] = cNeg[i,:] - lr*v*w\n",
    "    return w_new,cPos_new,cNeg_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vecSGNS(W,C,doc,vocab,W2I,I2W,probs,winSize=2,k=4):\n",
    "    numTokens = len(doc)\n",
    "    for i in range(numTokens):\n",
    "        for j in range(i-winSize,i+winSize):\n",
    "            if j != i and j >= 0 and j < numTokens:\n",
    "                wIdx = W2I[doc[i]]\n",
    "                posIdx = W2I[doc[j]]\n",
    "                w = W[wIdx,:]\n",
    "                cPos = C[posIdx,:]\n",
    "                cNeg = np.zeros((k,C.shape[1]))\n",
    "                m = 0\n",
    "                negIdx = []\n",
    "                for negC in np.random.choice(list(vocab),k,list(probs)):\n",
    "                    negIdx.append(W2I[negC])\n",
    "                    cNeg[m,:] = C[W2I[negC],:]\n",
    "                    m += 1\n",
    "        w_new,cPos_new,cNeg_new = gradientStep(w,cPos,cNeg)\n",
    "        W[wIdx,:] = w_new\n",
    "        C[posIdx,:] = cPos_new\n",
    "        C[negIdx,:] = cNeg_new\n",
    "    return W,C\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(numWords,100)\n",
    "C = np.random.rand(numWords,100)\n",
    "W,C = word2vecSGNS(W,C,processed_corpus,vocab,W2I,I2W,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E = W+C\n",
    "#E = W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
